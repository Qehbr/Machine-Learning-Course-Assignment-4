{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:46:56.407568Z",
     "start_time": "2025-01-17T19:46:50.030990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from torchviz import make_dot\n",
    "\n",
    "# modules from YOLOv5\n",
    "from yolov5.models.common import DetectMultiBackend\n",
    "from yolov5.models.experimental import attempt_load"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:46:56.438343Z",
     "start_time": "2025-01-17T19:46:56.411764Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:46:56.517256Z",
     "start_time": "2025-01-17T19:46:56.487268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Paths\n",
    "mat_file_path = \"imagelabels.mat\"\n",
    "image_dir = \"images\"\n",
    "model_path = \"models/yolov5s-cls.pt\"\n",
    "\n",
    "mat_data = loadmat(mat_file_path)\n",
    "\n",
    "print(\"Keys in .mat file:\", mat_data.keys())\n",
    "\n",
    "labels = mat_data['labels'].squeeze()\n",
    "\n",
    "image_files = sorted(os.listdir(image_dir))\n",
    "\n",
    "assert len(labels) == len(image_files), \"Number of labels and images do not match!\"\n",
    "\n",
    "# create a DataFrame with image names and labels\n",
    "flowers = pd.DataFrame({\n",
    "    \"Image_Name\": image_files,\n",
    "    \"Label\": labels\n",
    "})"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in .mat file: dict_keys(['__header__', '__version__', '__globals__', 'labels'])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:46:56.548689Z",
     "start_time": "2025-01-17T19:46:56.533759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the dataset into train, validation, and test sets (50%, 25%, 25%)\n",
    "train_val, test = train_test_split(flowers, test_size=0.25, stratify=flowers['Label'])\n",
    "train, val = train_test_split(train_val, test_size=0.33, stratify=train_val['Label'])\n",
    "\n",
    "print(f\"Training set: {len(train)}, Validation set: {len(val)}, Test set: {len(test)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 4114, Validation set: 2027, Test set: 2048\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:46:56.579685Z",
     "start_time": "2025-01-17T19:46:56.565766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to fit pre-trained models\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization for pre-trained models\n",
    "])\n",
    "\n",
    "\n",
    "class FlowerDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transform):\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row[\"Image_Name\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = torch.tensor(row[\"Label\"] - 1, dtype=torch.long)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = FlowerDataset(train, image_dir, transform)\n",
    "val_dataset = FlowerDataset(val, image_dir, transform)\n",
    "test_dataset = FlowerDataset(test, image_dir, transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:46:56.609586Z",
     "start_time": "2025-01-17T19:46:56.595706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
    "    train_losses, val_losses, val_accuracies = [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        val_accuracies.append(correct / total)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, \"\n",
    "              f\"Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracies[-1]:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses, val_accuracies"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:46:56.640199Z",
     "start_time": "2025-01-17T19:46:56.625709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Get predictions\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = correct / total\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "\n",
    "    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "    return avg_loss, accuracy"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# YOLO V5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:48:33.743675Z",
     "start_time": "2025-01-17T19:48:31.393808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the YOLOv5 classification model\n",
    "model = DetectMultiBackend(model_path, device=device, dnn=False, data=None, fp16=False)\n",
    "stride, names, pt = model.stride, model.names, model.pt\n",
    "\n",
    "# Modify the model's head for your specific number of classes\n",
    "num_classes = flowers['Label'].nunique()\n",
    "\n",
    "# Load the model as a PyTorch model\n",
    "model_pt = attempt_load(model_path, device=device)\n",
    "# Replace the final layer\n",
    "in_features = model_pt.model[-1].linear.in_features\n",
    "model_pt.model[-1].linear = nn.Linear(in_features, num_classes).to(device)\n",
    "model = model_pt.to(device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model summary: 149 layers, 5453480 parameters, 0 gradients, 11.5 GFLOPs\n",
      "Fusing layers... \n",
      "Model summary: 149 layers, 5453480 parameters, 0 gradients, 11.5 GFLOPs\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:48:59.803521Z",
     "start_time": "2025-01-17T19:48:59.526298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)  # Batch size 1, 3 color channels, 224x224 resolution\n",
    "output = model(dummy_input)\n",
    "graph = make_dot(output, params=dict(model.named_parameters()))\n",
    "graph.render(\"yolo\", format=\"png\", cleanup=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yolo.png'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:07:45.528993Z",
     "start_time": "2025-01-17T19:03:25.443368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Train YOLOv5 model\n",
    "train_losses, val_losses, accuracies = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 4.1585, Val Loss: 3.6745, Val Accuracy: 0.2630\n",
      "Epoch 2/10, Train Loss: 3.3216, Val Loss: 2.9663, Val Accuracy: 0.4924\n",
      "Epoch 3/10, Train Loss: 2.6702, Val Loss: 2.4150, Val Accuracy: 0.6576\n",
      "Epoch 4/10, Train Loss: 2.1655, Val Loss: 1.9949, Val Accuracy: 0.7597\n",
      "Epoch 5/10, Train Loss: 1.7761, Val Loss: 1.6852, Val Accuracy: 0.7943\n",
      "Epoch 6/10, Train Loss: 1.4768, Val Loss: 1.4348, Val Accuracy: 0.8323\n",
      "Epoch 7/10, Train Loss: 1.2527, Val Loss: 1.2603, Val Accuracy: 0.8550\n",
      "Epoch 8/10, Train Loss: 1.0853, Val Loss: 1.1239, Val Accuracy: 0.8648\n",
      "Epoch 9/10, Train Loss: 0.9476, Val Loss: 1.0057, Val Accuracy: 0.8747\n",
      "Epoch 10/10, Train Loss: 0.8417, Val Loss: 0.9150, Val Accuracy: 0.8791\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:07:45.590479Z",
     "start_time": "2025-01-17T19:07:45.560837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Plot Accuracy and Cross-Entropy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(accuracies, label=\"Accuracy\")\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.title(\"Cross-Entropy Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:07:54.148324Z",
     "start_time": "2025-01-17T19:07:45.594479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test the trained model\n",
    "test_loss, test_accuracy = test_model(model, test_loader, criterion, device)\n",
    "print(f\"Final Test Loss: {test_loss:.5f}\")\n",
    "print(f\"Final Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.9324, Test Accuracy: 0.8765\n",
      "Final Test Loss: 0.93237\n",
      "Final Test Accuracy: 87.65%\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
