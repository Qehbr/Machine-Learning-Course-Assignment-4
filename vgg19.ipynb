{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:44:44.150903Z",
     "start_time": "2025-01-17T19:44:40.923851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import VGG19_Weights\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchviz import make_dot\n",
    "from torch.autograd import Variable"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:44:44.180886Z",
     "start_time": "2025-01-17T19:44:44.157422Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:44:44.256929Z",
     "start_time": "2025-01-17T19:44:44.227770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Paths\n",
    "mat_file_path = \"imagelabels.mat\"\n",
    "image_dir = \"images\"\n",
    "\n",
    "mat_data = loadmat(mat_file_path)\n",
    "\n",
    "print(\"Keys in .mat file:\", mat_data.keys())\n",
    "\n",
    "labels = mat_data['labels'].squeeze()\n",
    "\n",
    "image_files = sorted(os.listdir(image_dir))\n",
    "\n",
    "assert len(labels) == len(image_files), \"Number of labels and images do not match!\"\n",
    "\n",
    "# create a DataFrame with image names and labels\n",
    "flowers = pd.DataFrame({\n",
    "    \"Image_Name\": image_files,\n",
    "    \"Label\": labels\n",
    "})"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in .mat file: dict_keys(['__header__', '__version__', '__globals__', 'labels'])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:44:44.287683Z",
     "start_time": "2025-01-17T19:44:44.273118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the dataset into train, validation, and test sets (50%, 25%, 25%)\n",
    "train_val, test = train_test_split(flowers, test_size=0.25, stratify=flowers['Label'])\n",
    "train, val = train_test_split(train_val, test_size=0.33, stratify=train_val['Label'])\n",
    "\n",
    "print(f\"Training set: {len(train)}, Validation set: {len(val)}, Test set: {len(test)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 4114, Validation set: 2027, Test set: 2048\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:44:44.318814Z",
     "start_time": "2025-01-17T19:44:44.304564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to fit pre-trained models\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization for pre-trained models\n",
    "])\n",
    "\n",
    "class FlowerDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transform):\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row[\"Image_Name\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = torch.tensor(row[\"Label\"] - 1, dtype=torch.long)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = FlowerDataset(train, image_dir, transform)\n",
    "val_dataset = FlowerDataset(val, image_dir, transform)\n",
    "test_dataset = FlowerDataset(test, image_dir, transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:44:44.348688Z",
     "start_time": "2025-01-17T19:44:44.334509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
    "    train_losses, val_losses, val_accuracies = [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        val_accuracies.append(correct / total)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, \"\n",
    "              f\"Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracies[-1]:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses, val_accuracies"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:44:44.379734Z",
     "start_time": "2025-01-17T19:44:44.365292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Get predictions\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = correct / total\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "\n",
    "    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "    return avg_loss, accuracy"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# VGG19"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:44:45.227896Z",
     "start_time": "2025-01-17T19:44:44.396586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vgg19 = models.vgg19(weights=VGG19_Weights.DEFAULT)\n",
    "\n",
    "# Modify VGG19 for flower classification\n",
    "num_classes = len(flowers['Label'].unique())  # Number of flower classes\n",
    "vgg19.classifier[6] = torch.nn.Linear(vgg19.classifier[6].in_features, num_classes)\n",
    "vgg19 = vgg19.to(device)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:44:46.062569Z",
     "start_time": "2025-01-17T19:44:45.244906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)  # Batch size 1, 3 color channels, 224x224 resolution\n",
    "output = vgg19(dummy_input)\n",
    "graph = make_dot(output, params=dict(vgg19.named_parameters()))\n",
    "graph.render(\"vgg19\", format=\"png\", cleanup=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vgg19.png'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(vgg19.parameters(), lr=1e-4)\n",
    "\n",
    "# Train VGG19\n",
    "train_losses, val_losses, accuracies = train_model(vgg19, criterion, optimizer, train_loader, val_loader, num_epochs=10)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot Accuracy and Cross-Entropy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(accuracies, label=\"Accuracy\")\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.title(\"Cross-Entropy Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:12:43.710705Z",
     "start_time": "2025-01-17T19:12:32.553536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test the trained model\n",
    "test_loss, test_accuracy = test_model(vgg19, test_loader, criterion, device)\n",
    "print(f\"Final Test Loss: {test_loss:.5f}%\")\n",
    "print(f\"Final Test Accuracy: {test_accuracy * 100:.5f}%\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.7026, Test Accuracy: 0.8442\n",
      "Final Test Loss: 0.70261%\n",
      "Final Test Accuracy: 84.42383%\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
